{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install langchain_openai\n",
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR_7E4fGG9lQ",
        "outputId": "4d6f0344-7eb2-44d3-a1f6-4fe5aeededeb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.9-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.9\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m640.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.3,>=0.2.2 (from langchain_openai)\n",
            "  Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.35.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.2.2->langchain_openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3,>=0.2.2->langchain_openai)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (2.7.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (8.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_openai)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_openai)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Installing collected packages: orjson, jsonpointer, tiktoken, jsonpatch, langsmith, langchain-core, langchain_openai\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.11 langchain_openai-0.1.14 langsmith-0.1.83 orjson-3.10.6 tiktoken-0.7.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.11)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.2.6 langchain-text-splitters-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"sk-\")\n",
        "\n",
        "# Define the questionnaire answers\n",
        "answers = {\n",
        "    \"company_a\": \"Sodexo\",\n",
        "    \"industry\": \"facilities management and food services\",\n",
        "    \"company_b\": \"CoachHub\",\n",
        "    \"goal\": \"accelerate their leadership development across APMEA\",\n",
        "    \"achievement_1\": \"Scalable coaching programs powered by AI and analytics with local support\",\n",
        "    \"achievement_2\": \"Access to a diverse pool of 3,500 top certified coaches from around the world\",\n",
        "    \"achievement_3\": \"Unlimited, structured coaching sessions and flexibility 24/7 for a hybrid, mobile workforce\",\n",
        "    \"achievement_4\": \"Boost knowledge retention and engagement with global benchmarking\",\n",
        "    \"achievement_5\": \"Quick implementation with low administrative burden\",\n",
        "    \"professionals\": \"coachees\",\n",
        "    \"individual\": \"Sodexo's Head of FMCG Accounts, Jean Baptiste CALEMARD\",\n",
        "    \"cta\": \"explore the greater you\",\n",
        "    \"link\": \"https://bit.ly/3LMxIHg\"\n",
        "}\n",
        "\n",
        "# Define the prompt template with placeholders\n",
        "system_message = \"\"\"\n",
        "You are tasked with writing a social media post that highlights a successful collaboration between two entities. The tone should be professional, and the achievements should be presented in bullet points. Here's the format and style you should follow:\n",
        "𝗗𝗶𝗱 𝘆𝗼𝘂 𝗸𝗻𝗼𝘄? 75% of classroom-style training is forgotten if it's not implemented within 6 days after.\n",
        "\n",
        "Discover how {company_a}, a leader in {industry}, partnered with {company_b} to achieve {goal}:\n",
        "\n",
        "🚀 {achievement_1}\n",
        "🌎 {achievement_2}\n",
        "🌟 {achievement_3}\n",
        "🧠 {achievement_4}\n",
        "✅ {achievement_5}\n",
        "\n",
        "Join thousands of {professionals}, like {individual}, on a journey of growth and transformation to {cta}:\n",
        "{link}\n",
        "\"\"\"\n",
        "\n",
        "# Fill in the placeholders with the actual answers\n",
        "filled_system_message = system_message.format(\n",
        "    company_a=answers[\"company_a\"],\n",
        "    industry=answers[\"industry\"],\n",
        "    company_b=answers[\"company_b\"],\n",
        "    goal=answers[\"goal\"],\n",
        "    achievement_1=answers[\"achievement_1\"],\n",
        "    achievement_2=answers[\"achievement_2\"],\n",
        "    achievement_3=answers[\"achievement_3\"],\n",
        "    achievement_4=answers[\"achievement_4\"],\n",
        "    achievement_5=answers[\"achievement_5\"],\n",
        "    professionals=answers[\"professionals\"],\n",
        "    individual=answers[\"individual\"],\n",
        "    cta=answers[\"cta\"],\n",
        "    link=answers[\"link\"]\n",
        ")\n",
        "\n",
        "# Make LLM call for response\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": filled_system_message\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.8,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "# Extract and print the generated post\n",
        "post = response.choices[0].message.content.strip()\n",
        "print(\"Generated Post:\\n\", post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CofmCALGTlwa",
        "outputId": "4fa58eaa-e40c-4c38-830e-c4ce78c7d533"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Post:\n",
            " Did you know? A powerful collaboration can be a game-changer in achieving accelerated leadership development. Let's delve into the successful alliance between Sodexo and CoachHub that has brought about a significant transformation in the APMEA region. \n",
            "\n",
            "✅ Sodexo, a global player in facilities management and food services, joined hands with CoachHub, a frontrunner in digital coaching platforms. \n",
            "\n",
            "Here's a look at the breakthrough they achieved together:\n",
            "\n",
            "🔹 Leveraged AI and analytics to roll out scalable coaching programs, backed by local support\n",
            "🔹 Provided access to a diverse pool of 3,500 top certified coaches from across the globe\n",
            "🔹 Created a structure for unlimited, round-the-clock coaching sessions to cater to a hybrid, mobile workforce\n",
            "🔹 Enhanced knowledge retention and engagement through global benchmarking\n",
            "🔹 Ensured speedy implementation with minimal administrative workload\n",
            "\n",
            "The partnership has helped many, including Jean Baptiste CALEMARD, Sodexo's Head of FMCG Accounts, to embark on a journey of growth and transformation. \n",
            "\n",
            "Don't miss the opportunity to explore your potential to the fullest: https://bit.ly/3LMxIHg\n",
            "\n",
            "Join us in celebrating this successful collaboration – a testament to the power of strategic alliances in fostering growth and development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the conversation history\n",
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a social media manager generating posts based on given data.\"},\n",
        "    {\"role\": \"user\", \"content\": filled_system_message},\n",
        "    {\"role\": \"assistant\", \"content\": post}\n",
        "]\n",
        "\n",
        "# Define a function to ask questions about the post\n",
        "def ask_question_about_post(question):\n",
        "    # Append the user's question to the conversation history\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "    # Define the prompt for answering questions\n",
        "    prompt = \"\"\"\n",
        "    You are an assistant answering questions about a generated social media post. Please provide concise, to the point and relevant responses based on the provided post. Make sure to include specific details and examples from the post where applicable.\n",
        "\n",
        "    Post:\n",
        "    {post}\n",
        "\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "\"\"\"\n",
        "\n",
        "    # Fill in the placeholders with the actual post and question\n",
        "    filled_prompt = prompt.format(post=post, question=question)\n",
        "\n",
        "    # Make the API call with the updated conversation history\n",
        "    interaction_response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=conversation_history + [{\"role\": \"user\", \"content\": filled_prompt}],\n",
        "        temperature=0.8,\n",
        "        top_p=1\n",
        "    )\n",
        "\n",
        "    # Extract and print the response\n",
        "    answer = interaction_response.choices[0].message.content.strip()\n",
        "\n",
        "    # Append the assistant's response to the conversation history\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Example questions\n",
        "questions = [\n",
        "    \"Can you describe the specific case study or transformation story you want to share?\",\n",
        "    \"What challenge or problem was addressed in this case?\",\n",
        "    \"What were the key results or outcomes achieved in this story?\",\n",
        "    \"Are there any data, quotes, or testimonials that illustrate the impact?\",\n",
        "    \"Is there a specific call-to-action?\",\n",
        "    \"Are there any specific hashtags you’d like to include?\",\n",
        "    \"Describe your desired tone and style.\"\n",
        "]\n",
        "\n",
        "# Ask questions and print the responses\n",
        "for question in questions:\n",
        "    answer = ask_question_about_post(question)\n",
        "    print(f\"Q: {question}\\nA: {answer}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPaoTcuyU3oY",
        "outputId": "41b6fa0e-35d7-4627-fce0-1173d33353d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Can you describe the specific case study or transformation story you want to share?\n",
            "A: The specific transformation story focuses on the successful collaboration between Sodexo and CoachHub, two entities that are leaders in their respective sectors. Together, they have revolutionized leadership development in the APMEA region.\n",
            "\n",
            "The partnership enabled Sodexo to leverage CoachHub's AI and analytics-powered platform to roll out scalable coaching programs. These programs have a diverse pool of over 3,500 top certified coaches worldwide, enabling Sodexo to create a structure for unlimited, 24/7 coaching sessions catering to a hybrid, mobile workforce.\n",
            "\n",
            "This collaboration resulted in enhanced knowledge retention and engagement through global benchmarking, achieved with minimal administrative workload. A significant transformation story is of Jean Baptiste CALEMARD, Sodexo's Head of FMCG Accounts, who embarked on a journey of growth and transformation through this partnership.\n",
            "\n",
            "To explore how this partnership can benefit you, visit https://bit.ly/3LMxIHg.\n",
            "\n",
            "Q: What challenge or problem was addressed in this case?\n",
            "A: The challenge addressed in this case was the need for accelerated leadership development within Sodexo, specifically in the APMEA region. The issue stemmed from a requirement for a scalable, flexible coaching program that could cater to a hybrid and mobile workforce, and promote knowledge retention and engagement. The partnership with CoachHub was aimed at overcoming these obstacles. Through this collaboration, Sodexo was able to leverage AI and analytics for their coaching programs, gain access to a diverse pool of certified coaches globally, and ensure quick implementation with minimal administrative workload.\n",
            "\n",
            "Q: What were the key results or outcomes achieved in this story?\n",
            "A: The key results and outcomes in this story of collaboration between Sodexo and CoachHub were:\n",
            "\n",
            "1. Successful leverage of AI and analytics to develop and implement scalable coaching programs with local support\n",
            "2. Access to a global network of 3,500 top certified coaches\n",
            "3. Creation of a flexible structure for unlimited, 24/7 coaching sessions to cater to a hybrid, mobile workforce\n",
            "4. Enhanced knowledge retention and engagement through global benchmarking\n",
            "5. Reduced administrative burdens through quick and efficient implementation of the program\n",
            "\n",
            "Moreover, this partnership enabled individuals like Jean Baptiste CALEMARD, Sodexo's Head of FMCG Accounts, to embark on a journey of growth and transformation.\n",
            "\n",
            "Q: Are there any data, quotes, or testimonials that illustrate the impact?\n",
            "A: While the provided post does not include specific data, quotes or testimonials, it does mention that the partnership between Sodexo and CoachHub has led to a significant transformation, with many benefiting from the program. One highlighted case is that of Jean Baptiste CALEMARD, Sodexo's Head of FMCG Accounts, who embarked on a journey of growth and transformation. Further details about the impact may be available on the linked webpage.\n",
            "\n",
            "Q: Is there a specific call-to-action?\n",
            "A: Yes, there's a specific call-to-action in the post. The call-to-action is \"Don't miss the opportunity to explore your potential to the fullest\". It invites readers to click on the provided link (https://bit.ly/3LMxIHg) to learn more about the partnership and possibly engage with the coaching services offered by CoachHub and Sodexo.\n",
            "\n",
            "Q: Are there any specific hashtags you’d like to include?\n",
            "A: Based on the context of the social media post, the following hashtags could be useful to improve visibility and reach:\n",
            "\n",
            "1. #SodexoCoachHubPartnership\n",
            "2. #LeadershipDevelopment\n",
            "3. #DigitalCoaching\n",
            "4. #AIinCoaching\n",
            "5. #GlobalCoaching\n",
            "6. #TransformationStory\n",
            "7. #StrategicAlliances\n",
            "8. #ProfessionalGrowth\n",
            "9. #SuccessStory\n",
            "\n",
            "Q: Describe your desired tone and style.\n",
            "A: The desired tone and style for the responses should be professional, informative, and engaging. It should be focused on delivering clear and concise information that accurately reflects the details provided in the original social media post. The style should also maintain a level of enthusiasm about the successful collaboration and the positive outcomes it has generated. Examples and specific details from the post should be seamlessly integrated into the responses to offer a comprehensive understanding of the topic.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Rqroct-VWFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}